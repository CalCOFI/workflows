---
title: "Ingest Ichthyo & Bottle to Working DuckLake"
execute:
  echo: true
  warning: false
editor_options:
  chunk_output_type: console
format:
  html:
    code-fold: true
editor:
  markdown:
    wrap: 72
---

## Overview {.unnumbered}

**Goal**: Integrate parquet outputs from individual ingest workflows into
the Working DuckLake, then create a frozen release for public access.

This workflow is the final step in the ingestion pipeline:

1.  Reads parquet files from individual ingest workflows
2.  Loads tables into Working DuckLake with provenance tracking
3.  Validates data quality and referential integrity
4.  Creates frozen DuckLake release (strips provenance columns)
5.  Uploads to GCS for public access

**Upstream workflows** (must complete first):

-   `ingest_swfsc.noaa.gov_calcofi-db.qmd` → ichthyo tables
-   `ingest_calcofi.org_bottle-database.qmd` → bottle/cast tables

```{mermaid}
%%| label: fig-workflow
%%| fig-cap: "Integration workflow: parquet → Working DuckLake → Frozen Release"

flowchart LR
    subgraph parquet["Parquet Outputs"]
        p1["swfsc.noaa.gov/calcofi-db"]
        p2["calcofi.org/bottle-database"]
    end

    subgraph working["Working DuckLake"]
        w1["Tables with provenance"]
        w2["_source_file, _source_uuid"]
    end

    subgraph frozen["Frozen Release"]
        f1["Clean tables"]
        f2["v2026.02"]
    end

    p1 --> working
    p2 --> working
    working --> frozen

    style parquet fill:#e3f2fd,stroke:#1565c0
    style working fill:#fff3e0,stroke:#ef6c00
    style frozen fill:#e8f4e8,stroke:#2e7d32
```

## Setup

```{r}
#| label: setup

devtools::load_all(here::here("../calcofi4db"))
librarian::shelf(
 CalCOFI/calcofi4db, DBI, dm, dplyr, DT, fs, glue, here, jsonlite,
  purrr, readr, stringr, tibble, tidyr,
  quiet = T)
options(readr.show_col_types = F)

# define parquet input directories
dir_parquet_ichthyo <- here("data/parquet/swfsc.noaa.gov/calcofi-db")
dir_parquet_bottle  <- here("data/parquet/calcofi.org/bottle-database")

# release version (YYYY.MM format)
release_version <- format(Sys.Date(), "v%Y.%m")
```

## Check Upstream Workflows

Verify that parquet outputs from upstream workflows exist.

```{r}
#| label: check_upstream

# check ichthyo parquet files
ichthyo_manifest <- file.path(dir_parquet_ichthyo, "manifest.json")
if (!file.exists(ichthyo_manifest)) {
  stop(glue("Missing ichthyo parquet outputs. Run ingest_swfsc.noaa.gov_calcofi-db.qmd first.\nExpected: {ichthyo_manifest}"))
}

ichthyo_meta <- jsonlite::read_json(ichthyo_manifest)
message(glue("Ichthyo parquet: {ichthyo_meta$total_rows} rows, created {ichthyo_meta$created_at}"))

# check bottle parquet files (optional for now)
bottle_manifest <- file.path(dir_parquet_bottle, "manifest.json")
bottle_available <- file.exists(bottle_manifest)

if (bottle_available) {
  bottle_meta <- jsonlite::read_json(bottle_manifest)
  message(glue("Bottle parquet: {bottle_meta$total_rows} rows, created {bottle_meta$created_at}"))
} else {
  message("Bottle parquet not available yet - will skip bottle tables")
}
```

## Load into Working DuckLake

Connect to Working DuckLake and load parquet tables with provenance tracking.

```{r}
#| label: connect_working

# get working ducklake connection (downloads from GCS if needed)
con <- get_working_ducklake()

# load spatial extension
load_duckdb_extension(con, "spatial")

message("Connected to Working DuckLake")
```

### Load Ichthyo Tables

```{r}
#| label: load_ichthyo

# list parquet files to load
ichthyo_files <- list.files(dir_parquet_ichthyo, pattern = "\\.parquet$", full.names = TRUE)

ichthyo_stats <- map_dfr(ichthyo_files, function(pqt_path) {
  tbl_name    <- tools::file_path_sans_ext(basename(pqt_path))
  source_file <- glue("parquet/swfsc.noaa.gov/calcofi-db/{basename(pqt_path)}")

  message(glue("  Loading: {tbl_name}"))

  # read parquet
  data <- arrow::read_parquet(pqt_path)

  # ingest with provenance
  stats <- ingest_to_working(
    con             = con,
    data            = data,
    table           = tbl_name,
    source_file     = source_file,
    source_uuid_col = NULL,  # parquet already has clean IDs
    mode            = "replace")

  stats
})

ichthyo_stats |>
  datatable(caption = "Ichthyo tables loaded to Working DuckLake")
```

### Load Bottle Tables (if available)

```{r}
#| label: load_bottle

if (bottle_available) {
  bottle_files <- list.files(dir_parquet_bottle, pattern = "\\.parquet$", full.names = TRUE)

  bottle_stats <- map_dfr(bottle_files, function(pqt_path) {
    tbl_name    <- tools::file_path_sans_ext(basename(pqt_path))
    source_file <- glue("parquet/calcofi.org/bottle-database/{basename(pqt_path)}")

    message(glue("  Loading: {tbl_name}"))

    # read parquet
    data <- arrow::read_parquet(pqt_path)

    # ingest with provenance
    stats <- ingest_to_working(
      con             = con,
      data            = data,
      table           = tbl_name,
      source_file     = source_file,
      source_uuid_col = NULL,
      mode            = "replace")

    stats
  })

  bottle_stats |>
    datatable(caption = "Bottle tables loaded to Working DuckLake")
} else {
  message("Skipping bottle tables (not available)")
}
```

## Validate Working DuckLake

```{r}
#| label: validate

# validate data quality
validation <- validate_for_release(con)

if (validation$passed) {
  message("Validation passed!")
  if (nrow(validation$checks) > 0) {
    validation$checks |>
      filter(status != "pass") |>
      datatable(caption = "Validation Warnings")
  }
} else {
  cat("Validation FAILED:\n")
  cat(paste("-", validation$errors, collapse = "\n"))
}
```

## Save Working DuckLake

```{r}
#| label: save_working

# save to GCS
save_working_ducklake(con)
message("Working DuckLake saved to GCS")
```

## List Working Tables

```{r}
#| label: list_tables

# list all tables with provenance stats
working_tables <- list_working_tables(con)
working_tables |>
  datatable(caption = "Working DuckLake tables with provenance")
```

## Create Frozen Release

Create a frozen (immutable) release for public access. This strips provenance
columns and creates a clean schema.
See [Frozen DuckLake](https://ducklake.select/2025/10/24/frozen-ducklake/) pattern.

```{r}
#| label: freeze_release

# define output directory for frozen release
dir_frozen <- here(glue("data/releases/{release_version}"))

message(glue("Creating frozen release: {release_version}"))

# get list of tables to freeze (exclude internal tables)
tables_to_freeze <- DBI::dbListTables(con) |>
  setdiff(c("_meta"))  # exclude metadata tables

# create frozen parquet files (strips provenance columns)
freeze_stats <- write_parquet_outputs(
  con              = con,
  output_dir       = file.path(dir_frozen, "parquet"),
  tables           = tables_to_freeze,
  strip_provenance = TRUE,
  compression      = "zstd")

freeze_stats |>
  datatable(caption = glue("Frozen release {release_version} statistics"))
```

### Create Release Notes

```{r}
#| label: release_notes

# generate release notes
release_notes <- glue("
# CalCOFI Database Release {release_version}

**Release Date**: {Sys.Date()}

## Tables Included

{paste('- ', freeze_stats$table, ' (', format(freeze_stats$rows, big.mark = ','), ' rows)', sep = '', collapse = '\n')}
## Total

- **Tables**: {nrow(freeze_stats)}
- **Total Rows**: {format(sum(freeze_stats$rows), big.mark = ',')}
- **Total Size**: {round(sum(freeze_stats$file_size) / 1024 / 1024, 1)} MB

## Source Workflows

- `ingest_swfsc.noaa.gov_calcofi-db.qmd` - Ichthyo tables (ichthyo, species, cruise, site, tow, net, etc.)
{if (bottle_available) '- `ingest_calcofi.org_bottle-database.qmd` - Bottle/cast tables' else ''}

## Changes

- Initial release with tidy ichthyo table structure
- Natural keys (cruise_key, ship_key) + sequential integer IDs
- Unified lookup table for vocabularies

## Access

Parquet files can be queried directly from GCS:

```r
library(duckdb)
con <- dbConnect(duckdb())
dbExecute(con, \"INSTALL httpfs; LOAD httpfs;\")
dbGetQuery(con, \"
  SELECT * FROM read_parquet(
    'https://storage.googleapis.com/calcofi-db/ducklake/releases/{release_version}/parquet/ichthyo.parquet')
  LIMIT 10\")
```

Or use calcofi4r:

```r
library(calcofi4r
con <- cc_get_db(version = '{release_version}')
```
")

# write release notes
writeLines(release_notes, file.path(dir_frozen, "RELEASE_NOTES.md"))
message(glue("Release notes written to {file.path(dir_frozen, 'RELEASE_NOTES.md')}"))

cat(release_notes)
```

### Upload Frozen Release to GCS

```{r}
#| label: upload_frozen
#| eval: false

# upload frozen release to GCS
# (set eval: true when ready to upload)

gcs_release_path <- glue("gs://calcofi-db/ducklake/releases/{release_version}")

message(glue("Uploading frozen release to {gcs_release_path}..."))

# upload all parquet files
parquet_files <- list.files(
  file.path(dir_frozen, "parquet"),
  pattern = "\\.parquet$",
  full.names = TRUE)

for (pqt_file in parquet_files) {
  gcs_path <- glue("{gcs_release_path}/parquet/{basename(pqt_file)}")
  put_gcs_file(pqt_file, gcs_path)
}

# upload manifest and release notes
put_gcs_file(
  file.path(dir_frozen, "parquet", "manifest.json"),
  glue("{gcs_release_path}/manifest.json"))

put_gcs_file(
  file.path(dir_frozen, "RELEASE_NOTES.md"),
  glue("{gcs_release_path}/RELEASE_NOTES.md"))

# update latest symlink (copy manifest to latest/)
put_gcs_file(
  file.path(dir_frozen, "parquet", "manifest.json"),
  "gs://calcofi-db/ducklake/releases/latest/manifest.json")

message(glue("Frozen release {release_version} uploaded to GCS"))
```

## Cleanup

```{r}
#| label: cleanup

# close database connection
close_duckdb(con)
message("Working DuckLake connection closed")

# summary
message(glue("\n=== Summary ==="))
message(glue("Working DuckLake: saved to GCS"))
message(glue("Frozen release: {release_version} created at {dir_frozen}"))
message(glue("Tables: {nrow(freeze_stats)}"))
message(glue("Total rows: {format(sum(freeze_stats$rows), big.mark = ',')}"))
```

## targets Integration

This workflow is designed to work with the targets pipeline. Add to `_targets.R`:
```r
# in workflows/_targets.R

tar_target(
  working_ducklake,
  {
    # ensure upstream workflows completed
    tar_read(ingest_swfsc)
    tar_read(ingest_bottle)  # when available

    # run this workflow
    quarto::quarto_render("workflows/ingest_ichthyo_bottle.qmd")

    # return manifest path for downstream targets
    here::here("data/releases", format(Sys.Date(), "v%Y.%m"), "parquet", "manifest.json")
  },
  format = "file"
)
```
