---
title: "Ingest Bottle Database"
execute:
  echo: true
  warning: false
editor_options: 
  chunk_output_type: console
format:
  html:
    code-fold: true  
editor: 
  markdown: 
    wrap: 72
---

## Overview {.unnumbered}

Source: [Bottle Database | CalCOFI.org](https://calcofi.org/data/oceanographic-data/bottle-database/)

- <https://calcofi.org/downloads/database/CalCOFI_Database_194903-202105_csv_16October2023.zip>

**Goal**: Ingest bottle database from source files, while:

- Ship names: fix typos, standardize abbreviations, and add missing ships.

- COMMENTs: append to field descriptions, and add missing fields.


```{r}
#| label: setup

librarian::shelf(
  DBI, dm, DT, glue, here, janitor, jsonlite, lubridate, purrr, readr, rlang, 
  tibble, tidyr, uuid,
  quiet = T)
options(readr.show_col_types = F)

# Source database connection
source(here("../apps_dev/libs/db.R"))

# define paths ---

# dataset with external data folder
dir_data     <- "/Users/bbest/My Drive/projects/calcofi/data"
provider     <- "calcofi.org"
dataset      <- "bottle-database"

dir_dataset  <- glue("{dir_data}/{provider}/{dataset}")
dir_ingest   <- here(glue("ingest/{provider}/{dataset}"))
bottle_csv   <- glue("{dir_dataset}/CalCOFI_Database_194903-202105_csv_16October2023/194903-202105_Bottle.csv")
cast_csv     <- glue("{dir_dataset}/CalCOFI_Database_194903-202105_csv_16October2023/194903-202105_Cast.csv")
# Open "Bottle Field Descriptions.csv" in Excel and Save As File Format: CSV UTF-8 (Comma delimited) (.csv)
m_bottle_csv <- glue("{dir_dataset}/Bottle Field Descriptions - UTF-8.csv")
m_cast_csv   <- glue("{dir_dataset}/Cast Field Descriptions.csv")
flds_rn_csv  <- glue("{dir_ingest}/flds_rename.csv")
  
if (!file.exists(flds_rn_csv)){
  
  # metadata
  m <- bind_rows(
    read_csv(m_cast_csv) |> 
      mutate(tbl = "cast") |> 
      relocate(tbl) |> 
      clean_names(),
    read_csv(m_bottle_csv) |>
      mutate(tbl = "bottle") |> 
      relocate(tbl) |> 
      clean_names()) |> 
    rename(
      fld_csv     = field_name) |> 
    mutate(
      fld_clean   = make_clean_names(fld_csv),
      fld_db      = fld_clean,
      ingest_note = "",
      comment     = pmap_chr(
        list(description, units, fld_csv), 
        \(description, units, fld_csv){
          list(
            description = description, 
            units       = units, 
            source      = glue("{basename(bottle_csv)}.{fld_csv}")) |> 
            toJSON(auto_unbox=T) })) |> 
    relocate(fld_clean, fld_db, note, .after = "fld_csv")
  
  write_excel_csv(m, flds_rn_csv) # UTF-8 encoding
  
  message(glue(
    "Please modify columns for data ingestion:
       {flds_rn_csv}
     - fld_db: (optionally making blank to exclude); 
     - note: notes for ingestion; and 
     - comment: for metadata description in JSON format"))
}
m <- read_csv(flds_rn_csv)

m |> 
  slice(48) |> 
  select(7) |> 
  datatable()
```

```{r}
#| label: fix ship.ship_nodc IS NA

dbExecute(con_dev, "UPDATE ship SET ship_nodc = '32BH' WHERE ship_key = 'BH' AND ship_nodc IS NULL")
stopifnot(tbl(con_dev, "ship") |>  filter(is.na(ship_nodc)) |> collect() |> nrow() == 0)
```

```{r}
#| label: cast.ship_nodc missing in ship

d_cast <- read_csv(cast_csv) |> 
  clean_names() |> 
  mutate(
    date = strptime(date, format = "%m/%d/%Y"))

d_cast_ship_miss <- d_cast |>
  select(ship_name, ship_nodc = ship_code, date) |> 
  group_by(ship_name, ship_nodc) |> 
  summarize(
    n_casts = n(),
    date_min = min(date),
    date_max = max(date),
    .groups = "drop") |> 
  anti_join(
    tbl(con_dev, "ship") |> 
      collect(),
    by = "ship_nodc")
#   ship_name             ship_nodc n_casts date_min            date_max           
#   <chr>                 <chr>       <int> <dttm>              <dttm>             
# 1 ARGO                  31AR            4 1962-01-11 00:00:00 1962-01-17 00:00:00
# 2 DAVID PHILLIP DOLPHIN 33DP           34 1973-05-23 00:00:00 1973-05-27 00:00:00
# 3 RV BELL M SHIMADA     325S          670 2010-09-24 00:00:00 2021-05-13 00:00:00
# 4 RV BELL M. SHIMADA    325S           67 2011-04-09 00:00:00 2011-04-26 00:00:00
# 5 RV DAVID STARR JORDAN 03JD            1 1996-05-01 00:00:00 1996-05-01 00:00:00
# 6 RV OCEAN STARR        31OS          213 2012-07-03 00:00:00 2016-07-26 00:00:00
# 7 RV REUBEN LASKER      33RL          464 2016-01-07 00:00:00 2021-02-03 00:00:00
# 8 RV SALLY RIDE         33SR          514 2016-11-06 00:00:00 2020-10-24 00:00:00
# 9 WESTWIND              32WC           11 1983-04-06 00:00:00 1983-04-07 00:00:00
d_cast_ship_miss
```

TODO: Update below to use the new [ingest_ices.dk_ship-ices](./ingest_ices.dk_ship-ices.html) workflow for ICES 4-letter ship code lookup.
  
```{r}
#| label: get_ship_nodc_refs

librarian::shelf(dplyr, purrr, readr, rvest)

ships_cc_url <- "https://www.calcofi.info/index.php/field-work/calcofi-ships/unols-ship-codes"
d_ships_cc <- tibble(
  url = read_html(ships_cc_url) |> 
    html_nodes("table a") |> 
    html_attr("href") |> 
    keep(~ grepl("/unols-ship-codes/\\d+-", .x)) |>   # Filter valid ship code links
    map_chr(~ paste0("https://www.calcofi.info", .x))) |> 
  mutate(
    data = map(
      url, \(url){
        read_html(url) |> 
          html_node("table") |>
          html_table(header = T) })) |> 
  unnest(data) |> 
  clean_names() |> 
  select(ship_nodc = ship_code, ship_name = ship, remarks, source_url = url) |> 
  mutate(
    remarks = na_if(remarks, ""))
write_csv(d_ships_cc, here("data/ships_calcofi.csv"))

ships_nodc_url <- "https://www.nodc.noaa.gov/OC5/WOD/CODES/s_3_platform.html"
d_ships_nodc <- read_html(ships_nodc_url) |> 
  html_node("table")  |> 
  html_table(header = T) |> 
  clean_names() |> 
  select(ship_nodc = nodc_code, p = platform_name) |> 
  mutate(
    ship_name = str_replace(p, "(.*) \\(.*\\)", "\\1"),
    remarks   = map_chr(p, \(p){
      if (!str_detect(p, "\\(")) return(NA)
      str_replace(p, "(.*) \\((.*)\\)", "\\2") }),
    source_url = ships_nodc_url) |> 
  select(ship_nodc, ship_name, remarks, source_url)
write_csv(d_ships_nodc, here("data/ships_nodc.csv"))
```


```{r}
d_ships <- c(
  cc   = "data/ships_calcofi.csv",
  nodc = "data/ships_nodc.csv") |> 
  enframe(name = "src", value = "csv") |> 
  mutate(
    data = map(csv, read_csv)) |> 
  unnest(data) |> 
  select(-csv, -source_url) # 15,937 Ã— 4
#   src   ship_nodc ship_name       remarks                         
#   <chr> <chr>     <chr>           <chr>                           
# 1 cc    90UW      11TH PJATILETKA OCL REQUEST                     
# 2 cc    90TU      1500 LET KIYEVU LYFB                            
# 3 cc    90FE      20-21           OCL                             
# 4 cc    90JO      203             ICES REQUEST  07Oct38 to 12Nov38
# 5 cc    73DE      30 DECEMBER     ICES REQUEST (years 1960 - 1961)
# 6 cc    76AJ      3-101           NA                              

db_ship <- tbl(con_dev, "ship") |> 
  collect() |> 
  rename(db_key = ship_key, db_name = ship_name, db_code = ship_nodc)

librarian::shelf(fuzzyjoin)

ck <- function(val, i, src, fld){
  if (fld == "ship_nodc")
    y <- d_ships |> filter(src == !!src, ship_nodc == !!val) |> pull(ship_name)
  if (fld == "ship_name")
    y <- d_ships |> filter(src == !!src, ship_name == !!val) |> pull(ship_nodc)
  if (length(y) == 0){
    y <- NA
  } else {
    y <- paste(y, collapse = "; ")
  }
  y
}

d_ship_matches <- d_cast_ship_miss |> 
  rename(csv_name = ship_name, csv_code = ship_nodc) |> 
  mutate(
    code_in_cc_name   = imap_chr(csv_code, ck, src="cc",   fld="ship_nodc"),
    code_in_nodc_name = imap_chr(csv_code, ck, src="nodc", fld="ship_nodc"),
    name_in_cc_code   = imap_chr(csv_name, ck, src="cc",   fld="ship_name"),
    name_in_nodc_name = imap_chr(csv_name, ck, src="nodc", fld="ship_name"),
    name_similar_db   = map_chr(csv_name, \(csv_name){
      wds_csv = str_split(csv_name, " ")[[1]]
      
      y <- db_ship |> 
        mutate(
          wds_db       = map_vec(db_name, str_split, " "),
          n_wds_match  = map_int(wds_db, \(wds_db){
            sum(wds_csv %in% wds_db) })) |> 
        filter(n_wds_match > 1) |> 
        arrange(desc(n_wds_match)) |> 
        head(1) |> 
        pull(db_name)
      if (length(y) == 0)
        return(NA)
      y })) |> 
  left_join(
    db_ship |> 
      select(name_similar_db = db_name, db_code),
    by = "name_similar_db")

d_ship_matches <- read_csv(glue("{dir_ingest}/ship_renames.csv"))
View(d_ship_matches)

%in% (  |> pull()),
    csv_code_in_nodc = csv_code %in% (d_ships |> filter(src == "nodc") |> pull(ship_nodc)),
    csv_name_in_cc   = csv_name %in% (d_ships |> filter(src == "cc")   |> pull(ship_name)),
    csv_name_in_nodc = csv_name %in% (d_ships |> filter(src == "nodc") |> pull(ship_name)))

rx_cruise <- "^([0-9]{4})-([0-9]{2})-([0-9]{2})-C-([0-9A-Z]{4})$"
d_cast |>
  mutate(
    date_ym   = str_replace(cruise_id, rx_cruise, "\\1-\\2-01") |> as.Date(),
    ship_nodc = str_replace(cruise_id, rx_cruise, "\\4")) |> 
  distinct(nodc) |> 
  anti_join(
    tbl(con_dev, "ship") |> 
      collect(),
    by = "nodc")

d_cast |>
  filter()
  select(ship_name, ship_nodc = ship_code) |> 
  distinct(ship_name, ship_nodc) |> 
  filter(ship_nodc == "31JD")
  anti_join(
    tbl(con_dev, "ship") |> 
      arrange(ship_name) |> 
      collect() |> 
      View(),
    by = "ship_nodc")

# confirm:
# - [Field Work > CalCOFI Ships > UNOLS Ship Codes](https://www.calcofi.info/index.php/field-work/calcofi-ships/unols-ship-codes)
# - [World Ocean Database: code tables](https://www.nodc.noaa.gov/OC5/WOD/CODES/s_3_platform.html)
#   ship_name             ship_nodc  status
# 1 ARGO                  31AR       new
# 2 DAVID PHILLIP DOLPHIN 33DP       new  
# 3 WESTWIND              32WC       new: 32WC -> 31WE
# 4 RV DAVID STARR JORDAN 03JD       old: 03JD -> 31JD
# 5 RV BELL M SHIMADA     325S       ship tbl: BELL M. SHIMADA 3322
  # WODC only: 3322	BELL M. SHIMADA (F/R/V;call sign WTED;built 10.2009;IMO9349069)
  # WODC,CalCOFI: 325S	SHIMADA
# 6 RV BELL M. SHIMADA    325S     
# 7 RV OCEAN STARR        31OS 	     ship: OCEAN STARR 32I1 (WODC)
# 8 RV REUBEN LASKER      33RL       ship: REUBEN LASKER 33UD (WODC)
# 9 RV SALLY RIDE         33SR       ship: SALLY RIDE 33P4 (WODC)
# NEW:
# - ARGO [31AR]
# - DAVID PHILLIP DOLPHIN [33DP]
# TYPOS:
# - RV DAVID STARR JORDAN [03JD] -> DAVID STARR JORDAN [31JD]
d_ships <- read_csv(here("data/calcofi-ships.csv"))  
d_ships |> 
  filter(ship_code == "31AR")


tbl(con_dev, "ship") |> 
  pull(nodc) |> nchar() |> table()
tbl(con_dev, "cruise") |> 
  pull(ship_key) |> unique() |> sort() |> table()


tbl(con_dev, "cruise") |> 
  left_join(
    tbl(con_dev, "ship") |> pull(nodc),
    by = "ship_key") |> 
  
  filter(
    nodc == "32BH") | is.na(nodc))



d_bottle <- read_csv(bottle_csv) |> 
  clean_names()

View(d_bottle)



```


## Report

```{r}
#| label: show_latest

dm_from_con(
  con_dev, 
  table_names = dbListTables(con_dev_only),
  # table_names = c("site_seg", "site", "cruise"),
  learn_keys  = T) |> 
  dm_set_colors(lightgreen = c(site_seg, grid)) |>
  dm_draw(view_type = "all")

d_eff <- tbl(con_dev, "site_seg") |> 
  mutate(
    year = year(time_beg)) |> 
  group_by(year) |> 
  summarize(
    time_hr   = sum(time_hr, na.rm = T),
    length_km = sum(length_km, na.rm = T)) |> 
  collect()

sum(d_eff$time_hr, na.rm = T)    # 302,516 hours; 12,604 days; 34.5 years
sum(d_eff$length_km, na.rm = T)  # 3,672,794 km
```



## Cleanup

```{r}
#| label: cleanup

# Close database connection
dbDisconnect(con)
```

## TODO

-   [ ] Add **indexes**.
-   [ ] Add **relationships** between primary keys.
-   [ ] Add **points** between `sites`
-   [ ] Add **segments** between `sites`.
-   [ ] Check all `type_new` are valid for db connection.
-   [ ] Check that all `flds_in` are in `flds_rn`.
-   [ ] Insert table and field SQL `COMMENT`s into database, using
    `comment` field + `workflow_md` (markdown with name and link) +
    source with tbl.fld
-   [ ] Review documentation for more comment descriptions at [Data \>
    Data Formats \|
    CalCOFI.org](https://calcofi.com/index.php?option=com_content&view=category&id=73&Itemid=993)
